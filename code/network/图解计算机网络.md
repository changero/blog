---
title: 图解计算机网络
date: 2020-12-18
---

## HTTP 请求

#### 请求头：

- Host
- Connection
- Content-Type
- Content-Encoding
- Content-Length

`GET`请求是`安全`且`幂等`的

`POST`请求是`不安全`且`非幂等`的

- 安全是指不会修改服务器上的的资源
- 幂等是指多次调用的结果都是相同的

HTTP 的优点是：简单、灵活和易扩展、跨平台

> HTTPS 就是 HTTP 与 TCP 之间增加了 SSL/TLS 安全传输层
>
> HTTP3 把 TCP 层换成了基于 UDP 的 QUIC

HTTP 的缺点是无状态（有好有坏），不安全

无状态的优点是不需要消耗额外的资源来保存、传输、处理状态信息，而缺点是无法识别之前以经处理过的客户端

#### HTTP1.1：

长连接

> HTTP1.0 的问题在于每一次 http 请求都要创建 TCP 连接（三次握手），在 HTTP1.1 中提出了持久连接，这样做的好处是减少了 TCP 连接的重复建立和断开所造成的额外开销，减轻了服务器端的负载

管道网络传输

在一个管道中可以同时发送多个请求，以前是一个管道内只能有一个请求，直到完成响应，才能发起下一次请求

队头堵塞

> 当顺序发送的请求序列中的一个请求因为某种原因被阻塞时，在后面排队的所有请求也一同被阻塞 了，会招致客户端一直请求不到数据，这也就是「**队头阻塞**」。**好比上班的路上塞车**

#### HTTP、HTTPS 的差异

|              HTTP               |                             HTTPS                              |
| :-----------------------------: | :------------------------------------------------------------: |
|            明文传输             |                            加密传输                            |
| 经过 3 个握手之后就可以传输数据 | 在经过 3 次握手之后还要进行 SSL/TLS 握手，才能进行加密报文传输 |
|           默认端口 80           |                          默认端口 443                          |
|                                 |  需要向 CA 申请数字证书，解决了窃听、篡改（指纹）、冒充的风险  |

防窃听：

传输数据前，客户端使用服务器`公钥`生成`会话密匙`，服务器通过`私钥`解密得到会话密匙，这个阶段是非对称加密

在传输数据的时候，客户端通过会话密匙加密明文数据，服务器同样用会话密匙解密得到数据，这个阶段是对称加密，响应阶段过程相同

整个过程称为混合加密，保证了数据不会被窃听

对称加密只有一个密匙，加解密速度快。是非对称加密有两个密匙，加解密速度慢

防篡改：

客户端加密明文数据之前，会通过摘要算法计算明文的摘要（指纹），将明文与指纹一起加密发送给服务端，服务端解密之后得到明文和摘要就可以知道数据是否被篡改

冒充：

> 客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密。 这就存在些问题，如何保证公钥不被篡改和信任度?
>
> 所以这里就需要借助第三方权威机构 CA (数字证书认证机构)，将**服务器公钥放在数字证书**(由数 字证书认证机构颁发)中，只要证书是可信的，公钥就是可信的

具体过程如下：

1. 服务器将自己的公钥提交到 CA
2. CA 使用自己的私钥将服务器的公钥进行签名，并颁发数字证书
3. 客户端请求的时候同时获取到公钥和数字证书。并使用 CA 的公钥确认服务器公钥的真实性
4. 使用公钥进行加密

CA 的公钥已经事先加入到了系统或者浏览器中

### HTTP1.1、HTTP2、HTTP3

HTTP/1.1 相比 HTTP/1.0 性能上的改进:

- 使用 TCP 长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。

- 支持管道(pipeline)网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求 出去，可以减少整体的响应时间。

但 HTTP/1.1 还是有性能瓶颈:

- 请求 / 响应头部(Header)未经压缩就发送，首部信息越多延迟越大。只能压缩 Body 的部分; 发送冗长的首部。每次互相发送相同的首部造成的浪费较多;

- 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队 头阻塞;

- 没有请求优先级控制; 请求只能从客户端开始，服务器只能被动响应。

HTTP2 相比于 HTTP1 做的改进

1. 头部压缩

   > HTTP/2 会**压缩头**(Header)如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会 帮你**消除重复的部分**。
   >
   > 这就是所谓的 HPACK 算法:在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表， 生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就**提高速度**了。

2. 二进制格式

   > HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了**二进制格式**，头信息和数据体都是 二进制，并且统称为帧(frame):**头信息帧和数据帧**。

3. 数据流

   > HTTP/2 的数据包不是按顺序发送的，同一个连接里面连续的数据包，可能属于不同的回应。因此，必 须要对数据包做标记，指出它属于哪个回应。
   >
   > 每个请求或回应的所有数据包，称为一个数据流( Stream )。每个数据流都标记着一个独一无二的编 号，其中规定客户端发出的数据流编号为奇数， 服务器发出的数据流编号为偶数
   >
   > 客户端还可以**指定数据流的优先级**。优先级高的请求，服务器就先响应该请求。

4. 多路复用

   > HTTP/2 是可以在**一个连接中并发多个请求或回应，而不用按照顺序一一对应**。
   >
   > 移除了 HTTP/1.1 中的串行请求，不需要排队等待，也就不会再出现「队头阻塞」问题，**降低了延迟， 大幅度提高了连接的利用率**。

5. 服务器推送

   > HTTP/2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务不再是被动地响应，也可以**主动** 向客户端发送消息。

HTTP2 的主要问题在于发生丢包的情况下，**所有 的** **HTTP** **请求都必须等待这个丢了的包被重传回来**。

所以 **HTTP/3** **把** **HTTP** **下层的** **TCP** **协议改成了** **UDP**!

![](https://pic.downk.cc/item/5fd9c1533ffa7d37b32c4ab3.png)
